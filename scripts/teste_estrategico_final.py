#!/usr/bin/env python3

import os
import time
import json
import requests
from pathlib import Path
import pandas as pd
from datetime import datetime

def test_transcription_simple(audio_file, engine, model):
    """Teste simples sem retry complexo"""
    url = "http://localhost:8000/transcribe"
    
    try:
        with open(audio_file, 'rb') as f:
            files = {'file': f}
            data = {'engine': engine, 'model': model}
            
            start_time = time.time()
            response = requests.post(url, files=files, data=data, timeout=30)
            end_time = time.time()
            
            if response.status_code == 200:
                result = response.json()
                text = result.get('text', '').strip()
                return {
                    'success': True,
                    'text': text,
                    'language': result.get('language', 'N/A'),
                    'duration': round(end_time - start_time, 2),
                    'word_count': len(text.split()) if text else 0,
                    'error': None
                }
            else:
                return {
                    'success': False,
                    'text': '',
                    'language': 'N/A',
                    'duration': round(end_time - start_time, 2),
                    'word_count': 0,
                    'error': f"HTTP {response.status_code}"
                }
    except Exception as e:
        return {
            'success': False,
            'text': '',
            'language': 'N/A',
            'duration': 0,
            'word_count': 0,
            'error': str(e)[:50] + "..."
        }

def main():
    print("ğŸ¯ === TESTE ESTRATÃ‰GICO: WHISPER TINY & BASE COM TODOS OS ÃUDIOS ===")
    print()
    
    # Verificar API
    try:
        response = requests.get("http://localhost:8000/health", timeout=5)
        if response.status_code != 200:
            print("âŒ API nÃ£o estÃ¡ funcionando")
            return
        print("âœ… API funcionando")
    except:
        print("âŒ NÃ£o foi possÃ­vel conectar Ã  API")
        return
    
    # Listar Ã¡udios
    audio_dir = Path("/workspaces/whisper/audios")
    audio_files = sorted(list(audio_dir.glob("*.ogg")) + list(audio_dir.glob("*.mp3")) + list(audio_dir.glob("*.wav")))
    
    print(f"ğŸ“ {len(audio_files)} arquivos de Ã¡udio encontrados")
    
    # Apenas os 2 modelos que sabemos que funcionam
    models = [
        ('whisper', 'tiny'),
        ('whisper', 'base')
    ]
    
    print(f"ğŸ¤– Testando {len(models)} modelos")
    print()
    
    results = []
    total_tests = len(audio_files) * len(models)
    test_count = 0
    
    for audio_file in audio_files:
        print(f"ğŸµ {audio_file.name}")
        
        for engine, model in models:
            test_count += 1
            print(f"   [{test_count:2d}/{total_tests}] {engine}/{model} ... ", end="", flush=True)
            
            result = test_transcription_simple(audio_file, engine, model)
            
            result.update({
                'audio_file': audio_file.name,
                'engine': engine,
                'model': model,
                'timestamp': datetime.now().isoformat()
            })
            
            results.append(result)
            
            if result['success']:
                text_preview = result['text'][:40] + "..." if len(result['text']) > 40 else result['text']
                print(f"âœ… {result['duration']:5.2f}s â”‚ {result['language']} â”‚ {result['word_count']:2d} palavras â”‚ \"{text_preview}\"")
            else:
                print(f"âŒ {result['error']}")
            
            time.sleep(1)  # Pausa entre testes
        
        print()
    
    # AnÃ¡lise final
    print("ğŸ“Š === RESULTADOS FINAIS ===")
    print()
    
    df = pd.DataFrame(results)
    
    # Salvar
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_file = f"/workspaces/whisper/teste_estrategico_{timestamp}.csv"
    df.to_csv(csv_file, index=False, encoding='utf-8')
    
    # EstatÃ­sticas
    total_tests = len(df)
    successes = df['success'].sum()
    success_rate = (successes / total_tests * 100) if total_tests > 0 else 0
    
    print("ğŸ“ˆ RESUMO GERAL")
    print("=" * 40)
    print(f"ğŸ§ª Testes executados: {total_tests}")
    print(f"âœ… Sucessos: {successes}")
    print(f"âŒ Falhas: {total_tests - successes}")
    print(f"ğŸ“Š Taxa de sucesso: {success_rate:.1f}%")
    print()
    
    if successes > 0:
        successful = df[df['success'] == True]
        
        # ComparaÃ§Ã£o entre modelos
        print("ğŸ† COMPARAÃ‡ÃƒO ENTRE MODELOS")
        print("=" * 50)
        model_comparison = successful.groupby(['engine', 'model']).agg({
            'duration': ['mean', 'min', 'max'],
            'word_count': 'mean',
            'success': 'count'
        }).round(2)
        model_comparison.columns = ['Tempo_MÃ©dio', 'Tempo_MÃ­n', 'Tempo_MÃ¡x', 'Palavras_MÃ©dia', 'Sucessos']
        print(model_comparison)
        print()
        
        # Performance por Ã¡udio
        print("ğŸµ PERFORMANCE POR ÃUDIO")
        print("=" * 60)
        audio_performance = df.groupby('audio_file').agg({
            'success': ['sum', 'count'],
            'duration': 'mean'
        }).round(2)
        audio_performance.columns = ['Sucessos', 'Total', 'Tempo_MÃ©dio']
        audio_performance['Taxa_Sucesso'] = (audio_performance['Sucessos'] / audio_performance['Total'] * 100).round(1)
        print(audio_performance.sort_values('Taxa_Sucesso', ascending=False))
        print()
        
        # Melhores transcriÃ§Ãµes
        print("ğŸ“ MELHORES TRANSCRIÃ‡Ã•ES")
        print("=" * 60)
        best_transcriptions = successful.nlargest(5, 'word_count')
        for _, row in best_transcriptions.iterrows():
            print(f"ğŸµ {row['audio_file']}")
            print(f"ğŸ¤– {row['engine']}/{row['model']} â”‚ {row['duration']}s â”‚ {row['word_count']} palavras")
            text_clean = row['text'][:80] + "..." if len(row['text']) > 80 else row['text']
            print(f"ğŸ“ \"{text_clean}\"")
            print()
        
        # Velocidade
        fastest = successful.loc[successful['duration'].idxmin()]
        slowest = successful.loc[successful['duration'].idxmax()]
        
        print("âš¡ VELOCIDADE")
        print("=" * 30)
        print(f"ğŸš€ Mais rÃ¡pido: {fastest['engine']}/{fastest['model']} ({fastest['duration']}s)")
        print(f"ğŸŒ Mais lento: {slowest['engine']}/{slowest['model']} ({slowest['duration']}s)")
        print()
        
        print("ğŸ¯ RECOMENDAÃ‡ÃƒO")
        print("=" * 30)
        avg_tiny = successful[successful['model'] == 'tiny']['duration'].mean()
        avg_base = successful[successful['model'] == 'base']['duration'].mean()
        
        if avg_tiny < avg_base:
            print("ğŸ† Whisper TINY Ã© mais rÃ¡pido em mÃ©dia")
            print(f"   Tiny: {avg_tiny:.2f}s vs Base: {avg_base:.2f}s")
        else:
            print("ğŸ† Whisper BASE Ã© mais rÃ¡pido em mÃ©dia") 
            print(f"   Base: {avg_base:.2f}s vs Tiny: {avg_tiny:.2f}s")
    
    # Mostrar falhas se houver
    failed = df[df['success'] == False]
    if not failed.empty:
        print("\\nâŒ FALHAS")
        print("=" * 20)
        failure_summary = failed.groupby(['engine', 'model'])['error'].count()
        for (engine, model), count in failure_summary.items():
            print(f"   {engine}/{model}: {count} falhas")
    
    print()
    print("=" * 60)
    print(f"ğŸ’¾ Resultados salvos em: {csv_file}")
    print("ğŸ‰ AnÃ¡lise concluÃ­da!")

if __name__ == "__main__":
    main()