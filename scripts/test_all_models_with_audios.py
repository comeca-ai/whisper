#!/usr/bin/env python3

import os
import time
import json
import requests
from pathlib import Path
import pandas as pd
from datetime import datetime

def test_transcription(audio_file, engine, model):
    """Testa transcri√ß√£o com um modelo espec√≠fico"""
    url = "http://localhost:8000/transcribe"
    
    try:
        with open(audio_file, 'rb') as f:
            files = {'file': f}
            data = {'engine': engine, 'model': model}
            
            start_time = time.time()
            response = requests.post(url, files=files, data=data, timeout=120)
            end_time = time.time()
            
            if response.status_code == 200:
                result = response.json()
                return {
                    'success': True,
                    'text': result.get('text', ''),
                    'language': result.get('language', 'N/A'),
                    'duration': end_time - start_time,
                    'error': None
                }
            else:
                return {
                    'success': False,
                    'text': '',
                    'language': 'N/A',
                    'duration': end_time - start_time,
                    'error': f"HTTP {response.status_code}: {response.text}"
                }
    except Exception as e:
        return {
            'success': False,
            'text': '',
            'language': 'N/A',
            'duration': 0,
            'error': str(e)
        }

def get_available_models():
    """Obt√©m modelos dispon√≠veis da API"""
    try:
        response = requests.get("http://localhost:8000/models")
        if response.status_code == 200:
            return response.json()
        else:
            return None
    except Exception as e:
        print(f"Erro ao obter modelos: {e}")
        return None

def main():
    print("üß™ === TESTE ABRANGENTE DE TODOS OS MODELOS COM TODOS OS √ÅUDIOS ===")
    print()
    
    # Diret√≥rio dos √°udios
    audio_dir = Path("/workspaces/whisper/audios")
    if not audio_dir.exists():
        print(f"‚ùå Diret√≥rio n√£o encontrado: {audio_dir}")
        return
    
    # Listar √°udios
    audio_files = list(audio_dir.glob("*.ogg")) + list(audio_dir.glob("*.mp3")) + list(audio_dir.glob("*.wav"))
    if not audio_files:
        print("‚ùå Nenhum arquivo de √°udio encontrado")
        return
    
    print(f"üìÅ Encontrados {len(audio_files)} arquivos de √°udio:")
    for audio in audio_files:
        print(f"   - {audio.name}")
    print()
    
    # Obter modelos dispon√≠veis
    models_info = get_available_models()
    if not models_info:
        print("‚ùå N√£o foi poss√≠vel obter informa√ß√µes dos modelos")
        return
    
    print("ü§ñ Modelos dispon√≠veis:")
    available_engines = []
    
    if models_info['engines_available'].get('whisper', False):
        for model in models_info['whisper_models']:
            available_engines.append(('whisper', model))
            print(f"   - Whisper: {model}")
    
    if models_info['engines_available'].get('faster-whisper', False):
        for model in ['tiny', 'base', 'small', 'medium']:  # Modelos mais comuns
            available_engines.append(('faster-whisper', model))
            print(f"   - Faster Whisper: {model}")
    
    print(f"\nüìä Total de combina√ß√µes a testar: {len(audio_files)} √°udios √ó {len(available_engines)} modelos = {len(audio_files) * len(available_engines)} testes")
    print()
    
    # Executar testes
    results = []
    total_tests = len(audio_files) * len(available_engines)
    current_test = 0
    
    for audio_file in audio_files:
        print(f"üéµ Processando: {audio_file.name}")
        
        for engine, model in available_engines:
            current_test += 1
            print(f"   [{current_test}/{total_tests}] {engine}/{model}... ", end="", flush=True)
            
            result = test_transcription(audio_file, engine, model)
            
            # Adicionar informa√ß√µes do teste
            result.update({
                'audio_file': audio_file.name,
                'engine': engine,
                'model': model,
                'timestamp': datetime.now().isoformat()
            })
            
            results.append(result)
            
            if result['success']:
                print(f"‚úÖ {result['duration']:.2f}s")
            else:
                print(f"‚ùå {result['error']}")
        
        print()
    
    # Criar DataFrame para an√°lise
    df = pd.DataFrame(results)
    
    # Salvar resultados detalhados
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    detailed_csv = f"/workspaces/whisper/resultados_detalhados_{timestamp}.csv"
    df.to_csv(detailed_csv, index=False)
    print(f"üíæ Resultados detalhados salvos em: {detailed_csv}")
    
    # Gerar tabelas de an√°lise
    print("\nüìä === RESULTADOS E AN√ÅLISES ===")
    print()
    
    # Tabela 1: Taxa de Sucesso por Modelo
    print("üìà 1. TAXA DE SUCESSO POR MODELO")
    print("=" * 60)
    success_by_model = df.groupby(['engine', 'model']).agg({
        'success': ['count', 'sum']
    }).round(2)
    success_by_model.columns = ['Total_Testes', 'Sucessos']
    success_by_model['Taxa_Sucesso'] = (success_by_model['Sucessos'] / success_by_model['Total_Testes'] * 100).round(1)
    success_by_model['Taxa_Sucesso'] = success_by_model['Taxa_Sucesso'].astype(str) + '%'
    print(success_by_model)
    print()
    
    # Tabela 2: Tempo M√©dio por Modelo (s√≥ sucessos)
    print("‚è±Ô∏è 2. TEMPO M√âDIO DE PROCESSAMENTO (segundos)")
    print("=" * 60)
    successful_df = df[df['success'] == True]
    if not successful_df.empty:
        time_by_model = successful_df.groupby(['engine', 'model'])['duration'].agg(['mean', 'min', 'max']).round(2)
        time_by_model.columns = ['Tempo_M√©dio', 'Tempo_M√≠n', 'Tempo_M√°x']
        print(time_by_model)
    else:
        print("Nenhum teste bem-sucedido para an√°lise de tempo")
    print()
    
    # Tabela 3: Desempenho por √Åudio
    print("üéµ 3. DESEMPENHO POR ARQUIVO DE √ÅUDIO")
    print("=" * 80)
    audio_stats = df.groupby('audio_file').agg({
        'success': ['count', 'sum'],
        'duration': 'mean'
    }).round(2)
    audio_stats.columns = ['Total_Modelos', 'Sucessos', 'Tempo_M√©dio']
    audio_stats['Taxa_Sucesso'] = (audio_stats['Sucessos'] / audio_stats['Total_Modelos'] * 100).round(1)
    audio_stats['Taxa_Sucesso'] = audio_stats['Taxa_Sucesso'].astype(str) + '%'
    print(audio_stats)
    print()
    
    # Tabela 4: Melhores e Piores Resultados
    print("üèÜ 4. RANKING DE MODELOS")
    print("=" * 50)
    if not successful_df.empty:
        ranking = successful_df.groupby(['engine', 'model']).agg({
            'duration': 'mean',
            'success': 'count'
        }).round(2)
        ranking.columns = ['Tempo_M√©dio', 'Testes_Sucessos']
        ranking = ranking.sort_values('Tempo_M√©dio')
        print("üöÄ Mais R√°pidos (tempo m√©dio):")
        print(ranking.head())
        print()
    
    # Tabela 5: An√°lise de Erros
    failed_df = df[df['success'] == False]
    if not failed_df.empty:
        print("‚ùå 5. AN√ÅLISE DE ERROS")
        print("=" * 50)
        error_analysis = failed_df.groupby(['engine', 'model'])['error'].count()
        error_analysis.name = 'Quantidade_Erros'
        print(error_analysis)
        print()
    
    # Resumo final
    print("üìã === RESUMO EXECUTIVO ===")
    print("=" * 40)
    total_successful = df['success'].sum()
    total_tests = len(df)
    overall_success_rate = (total_successful / total_tests * 100)
    
    print(f"‚úÖ Testes realizados: {total_tests}")
    print(f"‚úÖ Sucessos: {total_successful}")
    print(f"‚ùå Falhas: {total_tests - total_successful}")
    print(f"üìä Taxa de sucesso geral: {overall_success_rate:.1f}%")
    
    if not successful_df.empty:
        fastest_model = successful_df.loc[successful_df['duration'].idxmin()]
        print(f"üöÄ Modelo mais r√°pido: {fastest_model['engine']}/{fastest_model['model']} ({fastest_model['duration']:.2f}s)")
        
        avg_time = successful_df['duration'].mean()
        print(f"‚è±Ô∏è Tempo m√©dio geral: {avg_time:.2f}s")
    
    print()
    print("üíæ Arquivos gerados:")
    print(f"   - {detailed_csv}")
    print()
    print("üéâ An√°lise completa finalizada!")

if __name__ == "__main__":
    main()